---
title: "Report"
output:
  html_document:
    theme: readable
    toc : true
    toc_float: true
    code_folding: hide
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(patchwork)
library(plotly)
library(modelr)

knitr::opts_chunk$set(
  fig.width = 5,
  out.width = "85%",
  fig.align = "center",
  fig.height = 2.5
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Motivation 

Studying at Columbia University, except enjoying fascinating school life, we should always be concerned about the safety problem. Frequent email alerts, Citizen apps popping up, and terrifying news, they are all reminding us that there are many underlying unsafe factors around us. The New York government has made a public crime map at https://maps.nyc.gov/crime/.
The information in it, however, is way too redundant for a student as we are more concerned about the safety conditions around our campus and our places of residence. Luckily, NYPD has posted the up-to-date dataset that includes all valid felony, misdemeanor, and violation crimes reported to the New York City Police Department, and it includes more information that we are interested in, for example, the time of occurrence of the complaint, the victimâ€™s statistics. After analyzing the dataset, we can have a more comprehensive understanding about the crimes around us. Finally, we want to draw a fine map locating the crime incidents around our campus, informing us what time may be more dangerous and we can avoid activities at that time. The map will give students the option of looking up when they go outside most often to help them more accurately determine the likelihood of danger. We also want this result to help all the staff and students in Columbia University have an opportunity to evaluate the risk, avoid the danger, and allow them to access crime rates in the areas they care about to keep themselves safe.


## Related work and thoughts about our project

When we were looking for information about the crime rate near Columbia University, we saw the paper "Columbia stabbing puts spotlight on school's poor crime, safety record" which talked about some crimes in New York City. It inspired us to research more about the crime near Columbia University such as where and when the crime rate is higher and then we can try to avoid dangerous places to avoid being hurt. Besides some introduction to crime, there is also a pie chart in the paper, which makes us know the proportion of some types of criminal events directly. But this pie chart only provides a general summary of criminal events, and we think there are many details that can be added. Therefore, we want to analyze the crime rate near Columbia University according to our data set, and give the distribution more intuitively through some plots. This is the link of the paper: https://nypost.com/2021/12/04/columbia-grad-student-murder-puts-spotlight-on-crime-safety-record/.

Besides, a website which includes some crime data in US also inspired us. There are some very valuable plots on this website, such as comparing the crime rate of New York and the United States through a line plot, comparing the crime rate of New York and cities of the same size, and ranking the cities that are most suitable for living. But what is not enough is that this website is too wide for staffs and students of Columbia University. After all, staffs and students of Columbia University in some regions hardly go there; and some of the statistics here are too broad, which encourages us to make some pictures and websites which focus on the crime rate near Columbia University and include more specific data, which can provide more help for students of Columbia University.This is the link of the website: https://realestate.usnews.com/places/new-york/new-york-city/crime


## Aim of this project

* We hope to use the map on the website to answer which time period and which place near Columbia University are experiencing security incidents, and which regions have higher security incidents. We originally wanted to express which area has a higher crime rate by the color depth on the map, but in the process of analysis, we thought that we could label the data on the area and make the map more accurate as much as possible, so that students in Columbia University could find it more easily.

## Data downloading and cleaning:

* The more current data is from NYC Opendata,  https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Current-Year-To-Date-/5uac-w243, including approximately 400,000 crime recordes of 2021-2022, and is recently updated. The historical data set is from https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Historic/qgea-i56i, which includes more data (approximately 8,000,000 recordes) but is not sufficient in data of 2022. We combined these two datasets and the final output dataset have around 8 million records. Therefore, this dataset is expected to be accurate, authoritative, prompt and worth analyzing.

* Since the main purpose of this product is to help all the staff and students in Columbia University, so we decide to let our map cover the Manhattan area, and in order to give them most meaningful results, we focus the year after 2010. Then, we do the following: 1. select the rows recording date later than 2010-01-01. 2. Select the borough as Manhattan. 3. select the variables we are interested in. 4. filter the latitude and longitude to limit it around Columbia campus (roughly). The latitude range is approximately from 86 street subway station to George Washing Bridge (West 178th street). The longitude range is from Hudson river to Harlem river and Central park. This region covers Columbia University campus (and CUIMC) and the neighborhood area. At the meanwhile, we filtered out those crimes happening in the residences (apartment, house...), so that this data can reflect the crimes we can encounter in our daily lives. After cleaning the data, there remains around 300,000 data, which is sufficient for analyzing. 

* We use the following items and rename them to do our project:

  + `id`: case id numbers.
  
  + `boro`: Manhattan area.
  
  + `year`: The year this specific case happened.
  
  + `month`: The month this specific case happened.
  
  + `day`: The day this specific case happened.
  
  + `hour`: The exact hour this specific case happened.
  
  + `minute`: The exact minute this specific case happened.
  
  + `second`: The exact second this specific case happened.
  
  + `success_fail`: Indicator of whether crime was successfully completed or attempted, but failed or was interrupted prematurely.
  
  + `level`: Level of offense: felony, misdemeanor, violation.
  
  + `description`: Description of offense corresponding with key code.
  
  + `location`: Specific location of occurrence in or around the premises; inside, opposite of, front of, rear of.
  
  + `susp_age`: the age of suspect.
  
  + `susp_race`: the race of suspect.
  
  + `susp_sex`: the sex of suspect.
  
  + `vic_age`: the age of victim.
  
  + `vic_race`: the race of victim.
  
  + `vic_sex`: the sex of victim.
  
  + `logitude`: Logitude at Global Coordinate System.
  
  + `latitude`: Latitude at Global Coordinate System.
   

## Exploratory analysis
In this part, we want to have an overall sense about the crimes around Columbia University campus (including CUIMC). 
We pictured the proportion of each level of crimes, and the characteristics of suspects and victims. We also focused on the total crime numbers across the years, showing a pattern of the fluctuation of offense number with the months and times, so that we can have an idea about when it will be more dangerous and need more caution. At the same time, we also captured some interesting point of offense number.

### Numerical characteristics
```{r EDA, message=F}
filter_data = read_csv("../data/full_filter_data.csv")
p <- c() # a list to save plots
p[[1]] <- ggplot(aes(x = level, fill = level), data = filter_data) + 
  geom_bar() +
  labs(x = "Crime Level", y = "Number") + guides(fill = "none")+
theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))

p[[2]] <- ggplot(aes(x = success_fail, fill = success_fail), data = 
  filter_data)+
    geom_bar()+
  labs(x = "Crime Completed or Not", y = "Number")+ guides(fill = "none") +
theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))

p[[1]] + p[[2]]
```

The number of misdemeanor crime is the most (62.1%), while the number of felony is approximately half of misdemeanor (28.7%). The least type is violation (10%). Here exists a selection bias, most of people would not report a violation to the police. This figure does not indicate violation crimes is the least type in reality. At the meanwhile, nearly all (98%) of the crimes are completed -- do not put your faith in luck that someone can help you, try to avoid them as much as you can! 

### Crime level examples
To have a closer look to the different levels, we listed top 5 descriptions from different level. 
```{r, message=F}
felony <- filter_data %>% 
  group_by(level, description) %>% 
  filter(level == "FELONY") %>% 
  summarise(number = n()) %>% 
  arrange(desc(number)) %>% 
  head(5)

mis <- filter_data %>% 
  group_by(level, description) %>% 
  filter(level == "MISDEMEANOR") %>% 
  summarise(number = n()) %>% 
  arrange(desc(number)) %>% 
  head(5)

vio <- filter_data %>% 
  group_by(level, description) %>% 
  filter(level == "VIOLATION") %>% 
  summarise(number = n()) %>% 
  arrange(desc(number)) %>% 
  head(5)
  
rbind(felony, mis, vio) %>% 
  knitr::kable(align = 'c')
```

### Portrait of suspects and victims {.tabset}

Next, we focus on the portrait of suspects and victims. We used age group, race and gender to characterize them.

#### Suspects' data
```{r, message=F}
filter_data %>% 
  filter(susp_age %in% c("<18", "18-24", "25-44", "45-64", "65+",
                         "UNKNOWN")) %>%
  mutate(susp_age = as.factor(susp_age)) %>% 
  count(susp_age, level) %>% 
  plot_ly(x = ~ susp_age, y = ~n, type = "bar", color = ~ level, colors = "viridis") %>% 
  layout(title = "Suspects' Age Group", xaxis = list(title = ""), yaxis = list(title = "Number"))

filter_data %>% 
  filter (susp_race != "(null)") %>% 
  mutate(susp_age = as.factor(susp_race)) %>% 
  count(susp_race, level) %>% 
  plot_ly(x = ~ susp_race, y = ~n, type = "bar", color = ~ level, colors = "viridis") %>% 
  layout(title = "Suspects' Race", xaxis = list(title = ""), yaxis = list(title = "Number"))

filter_data %>% 
  filter (susp_sex != "(null)")  %>% 
  mutate(susp_sex = as.factor(susp_sex)) %>% 
  count(susp_sex, level) %>% 
  mutate(susp_sex = recode(susp_sex, U = "Unknown", F = "Female", "M" = "Male")) %>% 
  plot_ly(x = ~ susp_sex, y = ~n, type = "bar", color = ~ level, colors = "viridis") %>% 
  layout(title = "Suspects' Sex", xaxis = list(title = ""), yaxis = list(title = "Number"))
```

#### Victims' data
```{r, message=F}
filter_data %>% 
  filter(vic_age %in% c("<18", "18-24", "25-44", "45-64", "65+",
                         "UNKNOWN")) %>%
  mutate(vic_age = as.factor(vic_age)) %>% 
  count(vic_age, level) %>% 
  plot_ly(x = ~ vic_age, y = ~n, type = "bar", color = ~ level, colors = "viridis") %>% 
  layout(title = "Victims' Age Group", xaxis = list(title = ""), yaxis = list(title = "Number"))

filter_data %>% 
  filter (vic_race != "(null)") %>% 
  mutate(vic_age = as.factor(vic_race)) %>% 
  count(vic_race, level) %>% 
  plot_ly(x = ~ vic_race, y = ~n, type = "bar", color = ~ level, colors = "viridis") %>% 
  layout(title = "Victims' Race", xaxis = list(title = ""), yaxis = list(title = "Number"))

filter_data %>% 
  filter (vic_sex %in% c("D", "E", "F", "M"))  %>% 
  mutate(vic_sex = as.factor(vic_sex)) %>% 
  count(vic_sex, level) %>% 
  mutate(vic_sex = recode(vic_sex, F = "Female", "M" = "Male")) %>% 
  plot_ly(x = ~ vic_sex, y = ~n, type = "bar", color = ~ level, colors = "viridis") %>% 
  layout(title = "Victims' Sex", xaxis = list(title = ""), yaxis = list(title = "Number"))
```
### {-}

Through the data, we can see that except unknown, suspects' age is centered at 25-44 years old, black man. As for the victim, the age group is still centered at 25-44 years old. But the race is more evenly spread, and female number is much more than the suspect group, we will have statistical test to reveal whether there is a difference in the gender of suspects and victims.

Next, we want to look into the fluctuation of crime cases among months and hours, to see if the case number have a correlation with time.

### Correlation of crime number with time
#### Month data
```{r message=F, fig.height=3.5}
data <- filter_data
month_data <- data %>%  
  group_by(year, month) %>% 
  summarise(number = n()) %>% 
  mutate(month = as.factor(month),
         year = as.factor(year))
month_data %>% 
  plot_ly(y = ~number, color = ~month, type = "box", colors = "viridis") %>% 
  layout(title = "Crime Number Across Months", xaxis = list(title = "Month"), yaxis = list(title = "Number"))
```
We can roughly see that, in summer there are more crimes, especially from May to August. December and February have fewer cases. We will verify if there is a significant difference between months in statistical testing part.

#### Hour data
```{r message=F, fig.height=3.5}
hour_data = data %>% 
  group_by(year, month, hour) %>% 
  summarise(number = n()) %>%
  mutate(hour = as.factor(hour),
    hour = fct_inseq(hour)) 
hour_data %>% 
  plot_ly(y = ~number, color = ~hour, type = "box", colors = "viridis") %>% 
  layout(title = "Crime Number Across Hours", xaxis = list(title = "Hour"), yaxis = list(title = "Number"))
```
Obvious pattern. It's counter-intuitive that the time with most cases is not in the midnight, but in the afternoon. Similarly, We will verify if there is a significant difference between months in statistical testing part.

#### Correlation with specific days
Normally the crime numbers between days are quite alike, but admittedly there can be some days that are more dangerous. For example, Halloween's Day is generally considered as unsafe. Here we show the days that have the most cases, also we want to see which days are more "peaceful".
```{r message=F}
data %>% 
  group_by(month, day) %>% 
  summarise(number = n()) %>% 
  arrange(desc(number)) %>% 
  head( 5) %>% 
  knitr::kable(align = 'c', caption = "Days with most crimes")

data %>% 
  group_by(month, day) %>% 
  summarise(number = n()) %>% 
  arrange((number)) %>%
  filter(month != 2 & day != 29) %>% 
  head(5) %>% 
  knitr::kable(align = 'c', caption = "Days with least crimes")
```
The crime numbers in each day across years also varies a lot. It's a interesting finding that New Years' day enjoys the most crime cases, and the second is International Children's Day (sadly).  The days with fewest crimes is around Chirstmas Holiday, when most people will stay safely with their family at home.

## Statistical analysis

### Anova test - suspects' gender
Whether there is a significant difference in the number of male and female suspects. We calculate how many male and female suspects in month, year, then plot the disturbution of number of male and female suspects.
```{r, message=F, fig.height=3.2,  out.width = "85%"}
data <- read_csv("../data/full_filter_data.csv")

gender_data <- data %>%  
  group_by(year, month, susp_sex) %>% 
  summarise(number = n()) %>% 
  mutate(susp_sex = as.factor(susp_sex)) %>%
  filter(susp_sex %in% c("F", "M", "U"))
aov_model_1 <- aov(number ~ susp_sex, data = gender_data)

aov_model_1 %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 4, align = 'c')
  
```
There is a significant difference in the number of male and female suspects. Through the boxplot in EDA part, we could easily see that male is more likely to be suspects than females if we consider the unknown.

### T test - victims' gender
We wonder whether there is a significant difference in the number of male and female victims. So we calculate how many male and female victims in month, year, then plot the disturbution of number of male and female victims. And I also do the same steps for vic_sex include D=Business/Organization,
E=PSNY/People of the State of New York.

```{r, message=F, fig.height=3.2,  out.width = "85%"}
data <- read_csv("../data/full_filter_data.csv")
female <- data %>%  
  group_by(year, month, vic_sex) %>% 
  summarise(number = n()) %>% 
  mutate(vic_sex = as.factor(vic_sex)) %>%
  filter(vic_sex %in% c("F"))

male <- data %>%  
  group_by(year, month, vic_sex) %>% 
  summarise(number = n()) %>% 
  mutate(vic_sex = as.factor(vic_sex)) %>%
  filter(vic_sex %in% c("M"))

t.test(pull(female, number), pull(male, number)) %>% broom::glance() %>% 
  knitr::kable(digits = 4, align = 'c')
```
There is a significant difference in the number of male and female suspects. Through the boxplot, though compared to the suspect, the female victim number rises a lot, male is still more likely to be victims than females.

### Logistic regression - suspects' gender and crime successful rate
```{r, message=F, fig.height=3.2}
data <- read_csv("../data/full_filter_data.csv")
gender_data_rate <- data %>%  
  filter(susp_sex %in% c("F", "M", "U")) %>%
  mutate(success_fail = ifelse(success_fail == "COMPLETED", 1, 0))

reg_successrate = glm(success_fail ~ susp_sex, family=binomial(link="logit"), data = gender_data_rate)

reg_successrate %>% 
  broom::tidy() %>%
  knitr::kable(digits = 4, align = 'c')
  
gender_data_rate %>% 
  group_by(year, success_fail, susp_sex) %>% 
  summarise(number = n()) %>%
  mutate(success_fail = ifelse(success_fail == 1, "COMPLETED", "ATTEMPTED")) %>%
  pivot_wider(
  names_from = "success_fail", 
  values_from = "number") %>%
  mutate(total = ATTEMPTED+COMPLETED, 
         rate = COMPLETED/total) %>%
  plot_ly(x = ~ susp_sex, y = ~ rate, type = "box", color = ~ susp_sex, colors = "viridis") %>% 
  layout(xaxis = list(title = "Suspects' Gender"), yaxis = list(title = "Rate"))

```

There is a significant relationship between gender of suspects and successful rate. Through the boxplot, we could see that distribution of the successful rate of male suspects is lower than distribution of the successful rate of female suspects.


### Logistic regression - victims' gender and crime successful rate
```{r, message=F, fig.height=3.2}
data <- read_csv("../data/full_filter_data.csv")
gender_data_rate_1 <- data %>%  
  filter(vic_sex %in% c("F", "M")) %>%
  mutate(success_fail = ifelse(success_fail == "COMPLETED", 1, 0))

reg_successrate_1 = glm(success_fail ~ vic_sex, family=binomial(link="logit"), data = gender_data_rate_1)

reg_successrate_1 %>% 
  broom::tidy() %>%
  knitr::kable(digits = 4, align = 'c')


gender_data_rate_1 %>% 
  group_by(year, success_fail, vic_sex) %>% 
  summarise(number = n()) %>%
  mutate(success_fail = ifelse(success_fail == 1, "COMPLETED", "ATTEMPTED")) %>%
  pivot_wider(
  names_from = "success_fail", 
  values_from = "number") %>%
  mutate(total = ATTEMPTED+COMPLETED, 
         rate = COMPLETED/total) %>%
  plot_ly(x = ~ vic_sex, y = ~rate, type = "box", color = ~ vic_sex, colors = "viridis") %>% 
  layout(xaxis = list(title = "Victims' Gender"), yaxis = list(title = "Rate"))

```
Through the summary, we could see that crimes on male is significantly less to success (though still at a high ratio). According to the boxplot, we could see that distribution of the successful rate of male victims is also lower than distribution of the successful rate of male victims.

## Correlation between crime number and time

In the EDA part, we see that there exist some pattern in month and time in one day, but is it only random error and fluctuation, or there exist a significant difference?

### Anova test - crime number and month

We use group_by and summarize function to get the number of cases in each month and year, and then use the number of cases and month_data to make an ANOVA model to test whether there is a significant difference of number of crime cases among each month. 

```{r, message=F, fig.height=7}
data <- read_csv("../data/full_filter_data.csv")

month_data <- data %>%  
  group_by(year, month) %>% 
  summarise(number = n()) %>% 
  mutate(month = as.factor(month),
         year = as.factor(year))

aov_model <- aov(number ~ month, data = month_data) 

aov_model %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 4, align = 'c')
```

By the result above, we find that there are very significant difference in the crime numbers between months. Therefore, we utilized Tukey's method for post hoc tests, to see which months are different. 

Firstly, we use Turkey methods to analyze the ANOVA model, select the variables which p-value are smaller than 0.05, and arrange them by adj p_value. Then, we separate the contrast to A and B and add two variables "high" and "low" depending on whether estimate is larger than 0 to decide how A and B to fit high and low. Finally, we make a two panel plot to show the order of the months become "high" and "low" in the process of comparing. 

```{r, message=F, fig.height=3.2}
aov_posthoc <- TukeyHSD(aov_model, conf.level = .95) %>% 
  broom::tidy() %>% 
  filter(adj.p.value < 0.05) %>% 
  arrange(adj.p.value)

aov_posthoc %>% 
  head(5) %>% 
  knitr::kable(digits = 4 )

aov_group <- aov_posthoc %>% 
  separate(contrast, sep = "-", into = c("A", "B")) %>% 
  mutate(high = if_else(estimate > 0, true = A, false = B),
         low = if_else(estimate > 0, true = B, false = A)) %>% 
  mutate(high = fct_infreq(high),
         low = fct_infreq(low))

aov_fig1 <- aov_group %>% 
  ggplot(aes(x = high, fill = high)) +
  geom_bar(stat = "count") +
  labs(x = "Month", y = "Count", title = 
         "Months Having More Crimes \n in Multiple Comparisons") + guides(fill = "none")

aov_fig2 <- aov_group %>% 
  ggplot(aes(x = low, fill = low)) +
  geom_bar(stat = "count") +
  labs(x = "Month", y = "Count",title = 
         "Months Having Fewer Crimes \n in Multiple Comparisons") + guides(fill = "none")

aov_fig1 / aov_fig2
```

After pairwise independent multiple tests, we can draw the conclusion. We can roughly divide the months in one year into 3 groups. July, August, October, May, June, September generally have more crimes. February, January, November, December have fewer crimes. While March and April is at medium level, the crime number in this two months are significantly less than those months with excessive crimes, but also significantly more than months that have fewest crimes.

### Anova test - crime number and hour

Next, we repeat the steps, to see whether crime number at different time in a day have significant difference.We use group_by and summarize function to get the number of cases in each hour, arrange hour from 0 to 23, and then use the number of cases and hour_data to make an ANOVA model to test whether there is a significant difference of number of crime cases among each hour. 

```{r, message=F, fig.height=3.2}
# Is there differnece between case numbers in every hour? 
hour_data = data %>% 
  group_by(year, month, hour) %>% 
  summarise(number = n()) %>%
  mutate(hour = as.factor(hour),
    hour = fct_inseq(hour)) 

aov_hour <- aov(number ~ hour, data = hour_data)

aov_hour %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 4 )
```

By the result above, there are also significant difference in the mean number of crimes between different hours in one day.

Afterwards, we use Turkey methods to analyze the ANOVA model, steps is consistent with text above.

```{r, message=F, fig.height=5}
hour_posthoc <- TukeyHSD(aov_hour, conf.level = .95) %>% 
  broom::tidy() %>% 
  filter(adj.p.value < 0.05) %>% 
  arrange(adj.p.value)

hour_group <- hour_posthoc %>% 
  separate(contrast, sep = "-", into = c("A", "B")) %>% 
  mutate(high = if_else(estimate > 0, true = A, false = B),
         low = if_else(estimate > 0, true = B, false = A)) %>% 
  mutate(high = fct_infreq(high),
         low = fct_infreq(low))

aov_fig3 <- hour_group %>% 
  ggplot(aes(x = high, fill = high)) +
  geom_bar(stat = "count") +
  labs(x = "Hour", y = "Count", title = 
         "Hours Having More Crimes \n in Multiple Comparisons") + guides(fill = "none")+
  theme(plot.title = element_text(hjust = 0.5))

aov_fig4 <- hour_group %>% 
  ggplot(aes(x = low, fill = low)) +
  geom_bar(stat = "count") +
  labs(x = "Hour", y = "Count",title = 
         "Hours Having Fewer Crimes \n in Multiple Comparisons") + guides(fill = "none")+
  theme(plot.title = element_text(hjust = 0.5))

aov_fig3 / aov_fig4
```

The result corresponded with the findings in EDA part. The most dangerous hour is 12:00 - 21:00, all of them are at high ranks in the left figure. Comparatively, 1:00 - 9:00 is the most peaceful time. But it's our consensus that midnights are more hazardous. So we questioned on if more severe levels of crimes take place more in the midnights. 

### Anova test - FELONY crime number and hour

We use group_by and summarize function to get the number of cases in each level, hour, month and year, and select the data which level equals FELONY, then use the number of cases and hour_level to make an ANOVA model to test whether there is a significant difference of level of crime cases among each hour.  Then, we use Turkey methods to analyze the ANOVA model. The other steps is consistent with text above.

```{r, message=F, fig.height=5}
hour_level = data %>% 
  group_by(year, month, hour, level) %>% 
  filter(level == "FELONY") %>% 
  summarise(number = n()) %>%
  mutate(hour = as.factor(hour),
    hour = fct_inseq(hour)) 

aov_level <- aov(number ~ hour, data = hour_level)

aov_level %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 4 )

level_posthoc <- TukeyHSD(aov_level, conf.level = .95) %>% 
  broom::tidy() %>% 
  filter(adj.p.value < 0.05) %>% 
  arrange(adj.p.value)

level_group <- level_posthoc %>% 
  separate(contrast, sep = "-", into = c("A", "B")) %>% 
  mutate(high = if_else(estimate > 0, true = A, false = B),
         low = if_else(estimate > 0, true = B, false = A)) %>% 
  mutate(high = fct_infreq(high),
         low = fct_infreq(low))

aov_fig5 <- level_group %>% 
  ggplot(aes(x = high, fill = high)) +
  geom_bar(stat = "count") +
  labs(x = "Hour", y = "Count", title = 
         "Hours Having More Felony Crimes \n in Multiple Comparisons") + guides(fill = "none")+
  theme(plot.title = element_text(hjust = 0.5))

aov_fig6 <- level_group %>% 
  ggplot(aes(x = low, fill = low)) +
  geom_bar(stat = "count") +
  labs(x = "Hour", y = "Count",title = 
         "Hours Having Fewer Felony Crimes \n in Multiple Comparisons") + guides(fill = "none")+
  theme(plot.title = element_text(hjust = 0.5))

aov_fig5 / aov_fig6
```

The conclusion still holds true: afternoon is more dangerous. Be cautious! What time you think is safe may be dangerous than your thought.

## Build linear model for crime number prediction

All variables are categorical, except the response variable crime number. After plotting the histogram, we find the crime number is strongly right-skewed. Using boxcox transformation, we take logarithm of number and the data looks much more normally distributed. We decide to select meaningful age and male and female of gender to do the following prediction. Then we make a lm model to use month, hour, vic_age, vic_race, and vic_sex as predictors. Then we summary the model to get results to test significance of each predictor. Finally, we make a boxplot of the distribution of RMSE/IQR (normalized RMSE). 

```{r, message=F, warning=F, fig.height=3.6, out.width="65%"}

# find that group by day, every day there are too few cases, not appropriate for prediction, so we choose to ignore the day variable
set.seed(1244)
lm_data <- data %>% 
  filter(vic_age %in% c("<18", "18-24", "25-44", "45-64", "65+")) %>% 
  filter(vic_sex %in% c("M", "F")) %>%
  filter(vic_race != "(null)") %>% 
  mutate_at(c("month", "hour", "vic_age", "vic_race", "vic_sex"), as.factor) %>% 
  group_by(month, hour, vic_age, vic_race, vic_sex) %>% 
  summarise(log_number = log(n())) 

lm_model <- lm(log_number ~ . , data = lm_data)

options(digits = 4)

summary(lm_model, correlation = FALSE) %>% 
  broom::tidy() %>% 
  knitr::kable(align = 'c', caption = "Linear model parameters")


summary(lm_model) %>% 
  broom::glance() %>% 
  knitr::kable(align = 'c', caption = "Linear model statistics")
  
cv_result =
  crossv_mc(lm_data, 100) %>% 
  mutate(model = map(train, ~lm(log_number ~ ., data =.x))) %>% 
  mutate(rmse = map2_dbl(model, test,
                         ~rmse(model = .x, data = .y)))

sum_number <- summary(lm_data$log_number) %>% 
  broom::tidy()

IQR <- sum_number$q3 - sum_number$q1

cv_result %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse/IQR)) + geom_boxplot() +
  labs(x = "Model", y = "RMSE/IQR", title = "Distribution of RMSDIQR") +
  theme(plot.title = element_text(hjust = 0.5))
```

The model fits so well as the adjusted R squared is 0.756 with a extreme small p value. Moreover, we use normalized RMSE as the reference to evaluate the prediction ability of this model. It turns out to be good compared to the IQR, which means it's prediction error is less than $\frac{1}{3}$ IQR.


## Crimes Map around Columbia University

We used Shiny app to developed a map that can reflect the crime numbers at (and across) different years, months, hours, as well as the types of crime. From this map, we can always check it before we are heading to our destination, avoid the dangerous distinct, and choose a safe way.

Please access the map by this link : https://samuelsun.shinyapps.io/cu_shinymap/
  
## Summary

* For the suspect, the age group of 25-44 is the most; for the victim, the age group of 25-44 is also the most.

* Most of the suspects and victims are male.

* Most of the level of crime is MISDEMEANOR

* July, August, October, May, June, September generally have more crimesï¼›February, January, November, December have fewer crimesï¼›While March and April is at medium level, the crime number in this two months are significantly less than those months with excessive crimes, but also significantly more than months that have fewest crimes.

* The most dangerous hour is 12:00 - 21:00; comparatively, 1:00 - 9:00 is the most peaceful time. 

* Hour 16 and 17 has the high-level of the crime; hour 5 and 6 has the lower level of crime. 