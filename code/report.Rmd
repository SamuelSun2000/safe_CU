---
title: "Report"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: cerulean
runtime: shiny
---


Motivation {.sidebar}
-----------------------------------------------------------------------

* Studying at Columbia University, except enjoying fascinating school life, we should always be concerned about the safety problem. Frequent email alerts, Citizen apps popping up, and terrifying news, they are all reminding us that there are many underlying unsafe factors around us. The New York government has made a public crime map at https://maps.nyc.gov/crime/.
The information in it, however, is way too redundant for a student as we are more concerned about the safety conditions around our campus and our places of residence. Luckily, NYPD has posted the up-to-date dataset that includes all valid felony, misdemeanor, and violation crimes reported to the New York City Police Department, and it includes more information that we are interested in, for example, the time of occurrence of the complaint, the victimâ€™s statistics. After analyzing the dataset, we can have a more comprehensive understanding about the crimes around us. Finally, we want to draw a fine map locating the crime incidents around our campus, informing us what time may be more dangerous and we can avoid activities at that time. The map will give students the option of looking up when they go outside most often to help them more accurately determine the likelihood of danger. We also want this result to help all the staff and students in Columbia University have an opportunity to evaluate the risk, avoid the danger, and allow them to access crime rates in the areas they care about to keep themselves safe.


Related work and thoughts about our project {.sidebar}
-----------------------------------------------------------------------

* When we were looking for information about the crime rate near Columbia University, we saw the paper "Columbia stabbing puts spotlight on school's poor crime, safety record" which talked about some crimes in New York City. It inspired us to research more about the crime near Columbia University such as where and when the crime rate is higher and then we can try to avoid dangerous places to avoid being hurt. Besides some introduction to crime, there is also a pie chart in the paper, which makes us know the proportion of some types of criminal events directly. But this pie chart only provides a general summary of criminal events, and we think there are many details that can be added. Therefore, we want to analyze the crime rate near Columbia University according to our data set, and give the distribution more intuitively through some plots. This is the link of the paper: https://nypost.com/2021/12/04/columbia-grad-student-murder-puts-spotlight-on-crime-safety-record/.

* Besides, a website which includes some crime data in US also inspired us. There are some very valuable plots on this website, such as comparing the crime rate of New York and the United States through a line plot, comparing the crime rate of New York and cities of the same size, and ranking the cities that are most suitable for living. But what is not enough is that this website is too wide for staffs and students of Columbia University. After all, staffs and students of Columbia University in some regions hardly go there; and some of the statistics here are too broad, which encourages us to make some pictures and websites which focus on the crime rate near Columbia University and include more specific data, which can provide more help for students of Columbia University.This is the link of the website: https://realestate.usnews.com/places/new-york/new-york-city/crime


Initial questions about this project {.sidebar}
-----------------------------------------------------------------------

* We hope to use the map on the website to answer which time period and which place near Columbia University are experiencing security incidents, and which regions have higher security incidents. We originally wanted to express which area has a higher crime rate by the color depth on the map, but in the process of analysis, we thought that we could label the data on the area and make the map more accurate as far as possible, so that students in Columbia University could find it more easily.


Data {.sidebar}
-----------------------------------------------------------------------

Data import and clean:

* The data is from NYC Opendata, https://data.cityofnewyork.us/Public-Safety/NYPD-Complaint-Data-Current-Year-To-Date-/5uac-w243.This dataset is provided by NYPD, and is recently updated on Oct.19th. This dataset have 81.4K views and 16.7 downloads. Therefore, this dataset is expected to be accurate, authoritative, prompt and worth analyzing. 
* Since the main purpose of this product is to help all the staff and students in Columbia University, so we decide to let our map cover the Manhattan area, and in order to give them most meaningful results, we focus the year after 2010. Then, we do the fowllowing: 1. select the rows recording date later than 2010-01-01. 2. Select the borogh as Manhattan. 3. select the variables we are interseted in. 4. filter the latitude and longitude to limit it around columbia campus (roughly). The latitude range is approximately from 86 street subway station to George Washing Bridge (West 178th street). The longitude range is from Hudson river to Harlem river and Central park. This region covers Columbia University campus (and CUIMC) and the neighborhood area. You could find details here: [Data cleaning](code/data import and cleaning.Rmd)
* We use the following items to do our project:

  *`id`: case id numbers.
  
  *`bor0`: Manhattan area.
  
  *`year`: The year this specific case happened.
  
  *`month`: The month this specific case happened.
  
  *`day`: The day this specific case happened.
  
  *`hour`: The exact hour this specific case happened.
  
  *`minute`: The exact minute this specific case happened.
  
  *`second`: The exact second this specific case happened.
  
  *`success_fail`: Indicator of whether crime was successfully completed or attempted, but failed or was interrupted prematurely.
  
  *`level`: Level of offense: felony, misdemeanor, violation.
  
  *`description`: Description of offense corresponding with key code.
  
  *`location`: Specific location of occurrence in or around the premises; inside, opposite of, front of, rear of.
  
  *`susp_age`: the age of suspect.
  
  *`susp_race`: the race of suspect.
  
  *`susp_sex`: the sex of suspect.
  
  *`vic_age`: the age of victim.
  
  *`vic_race`: the race of victim.
  
  *`vic_sex`: the sex of victim.
  
  *`logitude`: Logitude at Global Coordinate System.
  
  *`latitude`: Latitude at Global Coordinate System.
   

Exploratory analysis {.sidebar}
-----------------------------------------------------------------------


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(patchwork)
library(plotly)
knitr::opts_chunk$set(
  fig.width = 5,
  out.width = "85%",
  fig.align = "center",
  fig.height = 2.5
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```
After reading this page, you will have an overall sense about the crimes around Columbia University campus (including CUIMC). 
We pictured the proportion of each level of crimes, and the charactristic of suspects and victims. We also focused on the total crime numbers across the years, showing a pattern of the fluctation of offense number with the months and times, so that we can have an idea about when it will be more dangerous and need more caution. At the same time, we also captured some interesting point of offense number.

### Overview about crimes around CU campus

By this plot, we could test which level of crime is the most.
```{r}
data <- read_csv("../data/full_filter_data.csv")
level_data <- data %>%  
  group_by(level) %>% 
  summarise(number = n())

level_data %>%
  ggplot(aes(x = level, y = number)) + 
  geom_point()
```

By this plot, we could test which group of age is the most for suspect.
```{r}
data <- read_csv("../data/full_filter_data.csv")
susp_age_data <- data %>%  
  group_by(susp_age) %>% 
  summarise(number = n()) %>%
  drop_na() %>%
  filter(susp_age != "UNKNOWN")

susp_age_data %>%
  ggplot(aes(x = susp_age, y = number)) + 
  geom_point()
```

By this plot, we could test which group of sex is the most for suspect.
```{r}
data <- read_csv("../data/full_filter_data.csv")
susp_sex_data <- data %>%  
  group_by(susp_sex) %>% 
  summarise(number = n()) %>%
  drop_na() 

susp_sex_data %>%
  ggplot(aes(x = susp_sex, y = number)) + 
  geom_point()
```

By this plot, we could test which group of age is the most for victim.
```{r}
data <- read_csv("../data/full_filter_data.csv")
vic_age_data <- data %>%  
  group_by(vic_age) %>% 
  summarise(number = n()) %>%
  drop_na() %>%
  filter(vic_age != "UNKNOWN")

vic_age_data %>%
  ggplot(aes(x = vic_age, y = number)) + 
  geom_point()
```

By this plot, we could test which group of sex is the most for victim.
```{r}
data <- read_csv("../data/full_filter_data.csv")
vic_sex_data <- data %>%  
  group_by(vic_sex) %>% 
  summarise(number = n()) %>%
  drop_na() %>%
  filter(vic_sex != "UNKNOWN")

vic_sex_data %>%
  ggplot(aes(x = vic_sex, y = number)) + 
  geom_point()
```

### Numerical characteristics

```{r EDA, message=F}
filter_data = read_csv("../data/full_filter_data.csv")
p <- c() # a list to save plots
p[[1]] <- ggplot(aes(x = level, fill = level), data = filter_data) + 
  geom_bar() +
  labs(x = "Crime Level", y = "Number") + guides(fill = "none")+
theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))

p[[2]] <- ggplot(aes(x = success_fail, fill = success_fail), data = 
  filter_data)+
    geom_bar()+
  labs(x = "Crime Completed or Not", y = "Number")+ guides(fill = "none") +
theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1))

p[[1]] + p[[2]]
```

The number of misdemeanor crime is the most (62.1%), while the number of felony is approximately half of misdemeanor (28.7%). The least type is violation (10%). Here exists a selection bias, most of people would not report a violation to the police. This figure does not indicate violation crimes is the least type in reality. At the meanwhile, nearly all (98%) of the crimes are completed -- do not put your faith in luck that someone can help you, try to avoid them as much as you can! 

### Crime level examples

To have a closer look to the different levels, we listed top 5 descriptions from different level. 
```{r, message=F}
felony <- filter_data %>% 
  group_by(level, description) %>% 
  filter(level == "FELONY") %>% 
  summarise(number = n()) %>% 
  arrange(desc(number)) %>% 
  head(5)

mis <- filter_data %>% 
  group_by(level, description) %>% 
  filter(level == "MISDEMEANOR") %>% 
  summarise(number = n()) %>% 
  arrange(desc(number)) %>% 
  head(5)

vio <- filter_data %>% 
  group_by(level, description) %>% 
  filter(level == "VIOLATION") %>% 
  summarise(number = n()) %>% 
  arrange(desc(number)) %>% 
  head(5)
  
rbind(felony, mis, vio) %>% 
  knitr::kable(align = 'c')
```

### Portrait of suspects and victims {.tabset}

Next, we focus on the portrait of suspects and victims. We used age group, race and gender to characterize them.

#### Suspects' data
```{r, message=F}
filter_data %>% 
  filter(susp_age %in% c("<18", "18-24", "25-44", "45-64", "65+",
                         "UNKNOWN")) %>%
  mutate(susp_age = as.factor(susp_age)) %>% 
  count(susp_age, level) %>% 
  plot_ly(x = ~ susp_age, y = ~n, type = "bar", color = ~ level, colors = "viridis") %>% 
  layout(title = "Suspects' Age Group", xaxis = list(title = ""), yaxis = list(title = "Number"))

filter_data %>% 
  filter (susp_race != "(null)") %>% 
  mutate(susp_age = as.factor(susp_race)) %>% 
  count(susp_race, level) %>% 
  plot_ly(x = ~ susp_race, y = ~n, type = "bar", color = ~ level, colors = "viridis") %>% 
  layout(title = "Suspects' Race", xaxis = list(title = ""), yaxis = list(title = "Number"))

filter_data %>% 
  filter (susp_sex != "(null)")  %>% 
  mutate(susp_sex = as.factor(susp_sex)) %>% 
  count(susp_sex, level) %>% 
  mutate(susp_sex = recode(susp_sex, U = "Unknown", F = "Female", "M" = "Male")) %>% 
  plot_ly(x = ~ susp_sex, y = ~n, type = "bar", color = ~ level, colors = "viridis") %>% 
  layout(title = "Suspects' Sex", xaxis = list(title = ""), yaxis = list(title = "Number"))
```

#### Victims' data
```{r, message=F}
filter_data %>% 
  filter(vic_age %in% c("<18", "18-24", "25-44", "45-64", "65+",
                         "UNKNOWN")) %>%
  mutate(vic_age = as.factor(vic_age)) %>% 
  count(vic_age, level) %>% 
  plot_ly(x = ~ vic_age, y = ~n, type = "bar", color = ~ level, colors = "viridis") %>% 
  layout(title = "Victims' Age Group", xaxis = list(title = ""), yaxis = list(title = "Number"))

filter_data %>% 
  filter (vic_race != "(null)") %>% 
  mutate(vic_age = as.factor(vic_race)) %>% 
  count(vic_race, level) %>% 
  plot_ly(x = ~ vic_race, y = ~n, type = "bar", color = ~ level, colors = "viridis") %>% 
  layout(title = "Victims' Race", xaxis = list(title = ""), yaxis = list(title = "Number"))

filter_data %>% 
  filter (vic_sex %in% c("D", "E", "F", "M"))  %>% 
  mutate(vic_sex = as.factor(vic_sex)) %>% 
  count(vic_sex, level) %>% 
  mutate(vic_sex = recode(vic_sex, F = "Female", "M" = "Male")) %>% 
  plot_ly(x = ~ vic_sex, y = ~n, type = "bar", color = ~ level, colors = "viridis") %>% 
  layout(title = "Victims' Sex", xaxis = list(title = ""), yaxis = list(title = "Number"))
```

### {-}

Through the data, we can see that except unknown, suspects' age is centered at 25-44 years old, black man. As for the victim, the age group is still centered at 25-44 years old. But the race is more evenly spread, and female number is much more than the suspect group, we will have statistical test to reveal whether there is a difference in the gender of suspects and victims.

Next, we want to look into the fluctuation of crime cases among months and hours, to see if the case number have a correlation with time.

### Correlation of crime number with time
#### Month data
```{r message=F, fig.height=3.5}
data <- filter_data
month_data <- data %>%  
  group_by(year, month) %>% 
  summarise(number = n()) %>% 
  mutate(month = as.factor(month),
         year = as.factor(year))
month_data %>% 
  plot_ly(y = ~number, color = ~month, type = "box", colors = "viridis") %>% 
  layout(title = "Crime Number Across Months", xaxis = list(title = "Month"), yaxis = list(title = "Number"))
```
We can roughly see that, in summer there are more crimes, especially from May to August. December and February have fewer cases. We will verify if there is a significant difference between months in statistical testing part.

#### Hour data
```{r message=F, fig.height=3.5}
hour_data = data %>% 
  group_by(year, month, hour) %>% 
  summarise(number = n()) %>%
  mutate(hour = as.factor(hour),
    hour = fct_inseq(hour)) 
hour_data %>% 
  plot_ly(y = ~number, color = ~hour, type = "box", colors = "viridis") %>% 
  layout(title = "Crime Number Across Hours", xaxis = list(title = "Hour"), yaxis = list(title = "Number"))
```
Obvious pattern. It's counter-intuitive that the time with most cases is not in the midnight, but in the afternoon. Similarly, We will verify if there is a significant difference between months in statistical testing part.

#### Correlation with specific days
Normally the crime numbers between days are quite alike, but admittedly there can be some days that are more dangerous. For example, Halloween's Day is generally considered as unsafe. Here we show the days that have the most cases, also we want to see which days are more "peaceful".
```{r message=F}
data %>% 
  group_by(month, day) %>% 
  summarise(number = n()) %>% 
  arrange(desc(number)) %>% 
  head( 5) %>% 
  knitr::kable(align = 'c', caption = "Days with most crimes")

data %>% 
  group_by(month, day) %>% 
  summarise(number = n()) %>% 
  arrange((number)) %>%
  filter(month != 2 & day != 29) %>% 
  head(5) %>% 
  knitr::kable(align = 'c', caption = "Days with least crimes")
```

The crime numbers in each day across years also varies a lot. It's a interesting finding that New Years' day enjoys the most crime cases, and the second is International Children's Day (sadly).  The days with fewest crimes is around Chirstmas Holiday, when most people will stay safely with their family at home. 


Statistical analysis {.sidebar}
-----------------------------------------------------------------------

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(patchwork)
library(plotly)
library(modelr)

knitr::opts_chunk$set(
  fig.width = 5,
  out.width = "60%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

Whether there is a significant difference in the number of male and female suspects. We calculate how many male and female suspects in month, year, then plot the disturbution of number of male and female suspects.

```{r}
data <- read_csv("../data/full_filter_data.csv")
gender_data <- data %>%  
  group_by(year, month, susp_sex) %>% 
  summarise(number = n()) %>% 
  mutate(susp_sex = as.factor(susp_sex)) %>%
  filter(susp_sex %in% c("F", "M", "U"))
aov_model_1 <- aov(number ~ susp_sex, data = gender_data)

summary(aov_model_1)

gender_data %>% 
  ggplot(aes(x = susp_sex, y = number, fill = susp_sex)) +
  geom_boxplot() +
  guides(fill = "none")  
```

* This is a significant difference in the number of male and female suspects. Through the boxplot, we could easily see that male is more likely to be suspencts than females if we consider the unknown.


Whether there is a significant difference in the number of male and female victims. We calculate how many male and female victims in month, year, then plot the disturbution of number of male and female victims. And I also do the same steps for vic_sex include D=Business/Organization, 
E=PSNY/People of the State of New York.

```{r}
data <- read_csv("../data/full_filter_data.csv")
gender_data_1 <- data %>%  
  group_by(year, month, vic_sex) %>% 
  summarise(number = n()) %>% 
  mutate(vic_sex = as.factor(vic_sex)) %>%
  filter(vic_sex %in% c("F", "M", "U"))
gender_data_2 <- data %>%  
  group_by(year, month, vic_sex) %>% 
  summarise(number = n()) %>% 
  mutate(vic_sex = as.factor(vic_sex)) %>%
  filter(vic_sex %in% c("F", "M", "D", "E"))
aov_model_1 <- aov(number ~ vic_sex, data = gender_data_1)

summary(aov_model_1)


gender_data_1 %>% 
  ggplot(aes(x = vic_sex, y = number, fill = vic_sex)) +
  geom_boxplot() +
  guides(fill = "none")
gender_data_2 %>% 
  ggplot(aes(x = vic_sex, y = number, fill = vic_sex)) +
  geom_boxplot() +
  guides(fill = "none") 
```

* This is a significant difference in the number of male and female suspects. Through the boxplot, we could see that male is more likely to be victims than females.


Whether there is a significant relationship between gender of suspects and sucessful rate.

```{r}
data <- read_csv("../data/full_filter_data.csv")
gender_data_rate <- data %>%  
  filter(susp_sex %in% c("F", "M", "U")) %>%
  mutate(success_fail = ifelse(success_fail == "COMPLETED", 1, 0))

reg_successrate = glm(success_fail ~ susp_sex, family=binomial(link="logit"), data = gender_data_rate)
summary(reg_successrate)


gender_data_rate %>% 
  group_by(year, success_fail, susp_sex) %>% 
  summarise(number = n()) %>%
  mutate(success_fail = ifelse(success_fail == 1, "COMPLETED", "ATTEMPTED")) %>%
  pivot_wider(
  names_from = "success_fail", 
  values_from = "number") %>%
  mutate(total = ATTEMPTED+COMPLETED, 
         rate = COMPLETED/total) %>%
  ggplot(aes(x = susp_sex, y = rate, fill = susp_sex)) +
  geom_boxplot()
```

* This is a significant relationship between gender of suspects and sucessful rate. Through the boxplot, we could see that distribution of the successful rate of male suspects is lower than distribution of the successful rate of male suspects.


Whether there is a significant relationship between gender of victims and sucessful rate.

```{r}
data <- read_csv("../data/full_filter_data.csv")
gender_data_rate_1 <- data %>%  
  filter(vic_sex %in% c("F", "M", "D", "E")) %>%
  mutate(success_fail = ifelse(success_fail == "COMPLETED", 1, 0))

reg_successrate_1 = glm(success_fail ~ vic_sex, family=binomial(link="logit"), data = gender_data_rate_1)
summary(reg_successrate_1)


gender_data_rate_1 %>% 
  group_by(year, success_fail, vic_sex) %>% 
  summarise(number = n()) %>%
  mutate(success_fail = ifelse(success_fail == 1, "COMPLETED", "ATTEMPTED")) %>%
  pivot_wider(
  names_from = "success_fail", 
  values_from = "number") %>%
  mutate(total = ATTEMPTED+COMPLETED, 
         rate = COMPLETED/total) %>%
  ggplot(aes(x = vic_sex, y = rate, fill = vic_sex)) +
  geom_boxplot()
```

* Through the summary, we could see that male is not significant to the whether victims is succedd or fail. According to the boxplot, we could see that distribution of the successful rate of male victims is also lower than distribution of the successful rate of male victims.


### Time pattern

In the EDA part, we see that there exist some pattern in month and time in one day, but is it only random error and fluctuation, or there exist a significant difference?

#### Month

We use group_by and summarize function to get the number of cases in each month and year, and then use the number of cases and month_data to make an ANOVA model to test whether there is a significant difference of number of crime cases among each month. 

```{r}
data <- read_csv("../data/full_filter_data.csv")

month_data <- data %>%  
  group_by(year, month) %>% 
  summarise(number = n()) %>% 
  mutate(month = as.factor(month),
         year = as.factor(year))

aov_model <- aov(number ~ month, data = month_data) 

aov_model %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 4 )
```

By the result above, we find that there are very significant difference in the crime numbers between months. Therefore, we utilized Tukey's method for post hoc tests, to see which months are different. 

Firstly, we use Turkey methods to analyze the ANOVA model, select the variables which p-value are smaller than 0.05, and arrange them by adj p_value. Then, we separate the contrast to A and B and add two variables "high" and "low" depending on whether estimate is larger than 0 to decide how A and B to fit high and low. Finally, we make a two panel plot to show the order of the months become "high" and "low" in the process of comparing. 

```{r}
aov_posthoc <- TukeyHSD(aov_model, conf.level = .95) %>% 
  broom::tidy() %>% 
  filter(adj.p.value < 0.05) %>% 
  arrange(adj.p.value)

aov_posthoc %>% 
  head(5) %>% 
  knitr::kable(digits = 4 )

aov_group <- aov_posthoc %>% 
  separate(contrast, sep = "-", into = c("A", "B")) %>% 
  mutate(high = if_else(estimate > 0, true = A, false = B),
         low = if_else(estimate > 0, true = B, false = A)) %>% 
  mutate(high = fct_infreq(high),
         low = fct_infreq(low))

aov_fig1 <- aov_group %>% 
  ggplot(aes(x = high, fill = high)) +
  geom_bar(stat = "count") +
  labs(x = "Month", y = "Count", title = 
         "Months Having More Crimes \n in Multiple Comparisons") + guides(fill = "none")

aov_fig2 <- aov_group %>% 
  ggplot(aes(x = low, fill = low)) +
  geom_bar(stat = "count") +
  labs(x = "Month", y = "Count",title = 
         "Months Having Fewer Crimes \n in Multiple Comparisons") + guides(fill = "none")

aov_fig1 + aov_fig2
```

After pairwise independent multiple tests, we can draw the conclusion. We can roughly divide the months in one year into 3 groups. July, August, October, May, June, September generally have more crimes. February, January, November, December have fewer crimes. While March and April is at medium level, the crime number in this two months are significantly less than those months with excessive crimes, but also significantly more than months that have fewest crimes.

#### Time

Next, we repeat the steps, to see whether crime number at different time in a day have significant difference.We use group_by and summarize function to get the number of cases in each hour, arrange hour from 0 to 23, and then use the number of cases and hour_data to make an ANOVA model to test whether there is a significant difference of number of crime cases among each hour. 

```{r}
# Is there differnece between case numbers in every hour? 
hour_data = data %>% 
  group_by(year, month, hour) %>% 
  summarise(number = n()) %>%
  mutate(hour = as.factor(hour),
    hour = fct_inseq(hour)) 

aov_hour <- aov(number ~ hour, data = hour_data)

aov_hour %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 4 )
```

Firstly, we use Turkey methods to analyze the ANOVA model, select the variables which p-value are smaller than 0.05, and arrange them by adj p_value. Then, we separate the contrast to A and B and add two variables "high" and "low" depending on whether estimate is larger than 0 to decide how A and B to fit high and low. Finally, we make a two panel plot to show the order of the hours become "high" and "low" in the process of comparing. 

By the result above, there are also significant difference in the mean number of crimes between different hours in one day.

```{r}
hour_posthoc <- TukeyHSD(aov_hour, conf.level = .95) %>% 
  broom::tidy() %>% 
  filter(adj.p.value < 0.05) %>% 
  arrange(adj.p.value)

hour_group <- hour_posthoc %>% 
  separate(contrast, sep = "-", into = c("A", "B")) %>% 
  mutate(high = if_else(estimate > 0, true = A, false = B),
         low = if_else(estimate > 0, true = B, false = A)) %>% 
  mutate(high = fct_infreq(high),
         low = fct_infreq(low))

aov_fig3 <- hour_group %>% 
  ggplot(aes(x = high, fill = high)) +
  geom_bar(stat = "count") +
  labs(x = "Hour", y = "Count", title = 
         "Hours Having More Crimes \n in Multiple Comparisons") + guides(fill = "none")

aov_fig4 <- hour_group %>% 
  ggplot(aes(x = low, fill = low)) +
  geom_bar(stat = "count") +
  labs(x = "Hour", y = "Count",title = 
         "Hours Having Fewer Crimes \n in Multiple Comparisons") + guides(fill = "none")

aov_fig3 + aov_fig4
```

The result corresponded with the findings in EDA part. The most dangerous hour is 12:00 - 21:00, all of them are at high ranks in the left figure. Comparatively, 1:00 - 9:00 is the most peaceful time. But it's our consensus that midnights are more hazardous. So we questioned on if more server levels of crime take place more in the midnights. 

We use group_by and summarize function to get the number of cases in each level, hour, month and year, and select the data which level equals FELONY, then use the number of cases and hour_level to make an ANOVA model to test whether there is a significant difference of level of crime cases among each hour.  Then, we use Turkey methods to analyze the ANOVA model, select the variables which p-value are smaller than 0.05, and arrange them by adj p_value. Then, we separate the contrast to A and B and add two variables "high" and "low" depending on whether estimate is larger than 0 to decide how A and B to fit high and low. Finally, we make a two panel plot to show the order of the hours become "high" and "low" in the process of comparing. 

```{r}
hour_level = data %>% 
  group_by(year, month, hour, level) %>% 
  filter(level == "FELONY") %>% 
  summarise(number = n()) %>%
  mutate(hour = as.factor(hour),
    hour = fct_inseq(hour)) 

aov_level <- aov(number ~ hour, data = hour_level)

aov_level %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 4 )

level_posthoc <- TukeyHSD(aov_level, conf.level = .95) %>% 
  broom::tidy() %>% 
  filter(adj.p.value < 0.05) %>% 
  arrange(adj.p.value)

level_group <- level_posthoc %>% 
  separate(contrast, sep = "-", into = c("A", "B")) %>% 
  mutate(high = if_else(estimate > 0, true = A, false = B),
         low = if_else(estimate > 0, true = B, false = A)) %>% 
  mutate(high = fct_infreq(high),
         low = fct_infreq(low))

aov_fig5 <- level_group %>% 
  ggplot(aes(x = high, fill = high)) +
  geom_bar(stat = "count") +
  labs(x = "Hour", y = "Count", title = 
         "Hours Having More Felony Crimes \n in Multiple Comparisons") + guides(fill = "none")

aov_fig6 <- level_group %>% 
  ggplot(aes(x = low, fill = low)) +
  geom_bar(stat = "count") +
  labs(x = "Hour", y = "Count",title = 
         "Hours Having Fewer Felony Crimes \n in Multiple Comparisons") + guides(fill = "none")

aov_fig5 + aov_fig6
```

The conclusion still holds true. Be cautious! What time you think is safe may be dangerous than your thought.


## Build a linear model for prediction

All variables are categorical, except the response variable crime number. After plotting the histogram, we find the crime number is strongly right-skewed. Using boxcox transformation, we take logrithm of number and the data looks much more normally distributed. We decide to select meaningful age and male and female of gender to do the following prediction. Then we make a lm model to use month, hour, vic_age, vic_race, and vic_sex as predictors. Then we summary the model to get results to test significance of each predictor. Finally, we make a boxplot of the distribution of RMSE/IQR

```{r}

# find that group by day, every day there are too few cases, not appropriate for prediction, so we choose to ignore the day variable

lm_data <- data %>% 
  filter(vic_age %in% c("<18", "18-24", "25-44", "45-64", "65+")) %>% 
  filter(vic_sex %in% c("M", "F")) %>%
  filter(vic_race != "(null)") %>% 
  mutate_at(c("month", "hour", "vic_age", "vic_race", "vic_sex"), as.factor) %>% 
  group_by(month, hour, vic_age, vic_race, vic_sex) %>% 
  summarise(log_number = log(n())) 

lm_model <- lm(log_number ~ . , data = lm_data)

options(digits = 4)

summary(lm_model, correlation = FALSE) %>% 
  broom::glance() %>% 
  knitr::kable()
  
cv_result =
  crossv_mc(lm_data, 100) %>% 
  mutate(model = map(train, ~lm(log_number ~ ., data =.x))) %>% 
  mutate(rmse = map2_dbl(model, test,
                         ~rmse(model = .x, data = .y)))

sum_number <- summary(lm_data$log_number) %>% 
  broom::tidy()

IQR <- sum_number$q3 - sum_number$q1

cv_result %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse/IQR)) + geom_boxplot() +
  labs(x = "", y = "RMSE/IQR", title = "Distribution of RMSDIQR")
```

We used normalized RMSE as the reference to evaluate the prediction ability of this model. It turnns of to be good.



Map {.sidebar}
-----------------------------------------------------------------------

### Crimes Map around Columbia University:


```{r, include=FALSE}
library(tidyverse)
library(plotly)
library(leaflet)

cu_df = read_csv("../data/full_filter_data.csv")
```


```{r, echo = FALSE}
sliderInput(
  inputId = 'year_range',
  label = h3('Year Range'),
  min = 2010, max = 2022, value = c(2021, 2022)
)

sliderInput(
  inputId = 'month_range',
  label = h3('Month Range'),
  min = 1, max = 12, value = c(1, 2)
)

sliderInput(
  inputId = 'hour_range',
  label = h3('Hour Range'),
  min = 0, max = 24, value = c(8, 18)
)

Level = cu_df %>% distinct(level) %>% pull()

radioButtons(
  inputId = 'level_choice',
  label = h3('Crime Level'),
  choices = Level,
  selected = 'VIOLATION'
)
```


### Safety Map around Columbia University

```{r, echo = FALSE}
content_main = paste(sep = "<br/>",
  "<b><a href='https://www.columbia.edu/'>Columbia University</a></b>",
  "2960 Broadway",
  "New York, NY 10027-6902"
)

content_cumc = paste(sep = "<br/>",
  "<b><a href='https://www.publichealth.columbia.edu/'>Columbia Mailman School for Public Health</a></b>",
  "West 168th Street, 722",
  "New York, NY 10032"
)

renderLeaflet({
  cu_df %>% 
    filter(
      year >= input[['year_range']][1],
      year <= input[['year_range']][2],
      month >= input[['month_range']][1],
      month <= input[['month_range']][2],
      hour >= input[['hour_range']][1],
      hour <= input[['hour_range']][2],
      level == input[['level_choice']]
    ) %>% 
    leaflet() %>% 
    setView(lng = -73.94184,lat = 40.8394, zoom = 14) %>% 
    addTiles() %>% 
    addPopups(-73.96249, 40.80747, content_main, options = popupOptions(closeButton = FALSE)) %>% 
    addPopups(-73.9434, 40.84259, content_cumc, options = popupOptions(closeButton = FALSE)) %>% 
    addMarkers(~longitude, ~latitude, clusterOptions = markerClusterOptions())
})
```



Summary {.sidebar}
-----------------------------------------------------------------------

* For the suspect, the age group of 25-44 is the most; for the victim, the age group of 25-44 is also the most.

* Most of the suspects and victims are male.

* Most of the level of crime is MISDEMEANOR







